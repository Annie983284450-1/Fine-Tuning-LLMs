This repository contains practical Jupyter notebooks and resources for fine-tuning Large Language Models (LLMs) for various NLP tasks, from simple prompting methods to advanced fine-tuning techniques.
```
pip install tensorflow torch transformers datasets

```
# Fine-Tuning-LLMs
Chatbot.ipynb: Provides a chatbot implementation that leverages fine-tuned LLMs. 

Specifically, 
- 1_PromptingFlanT5.ipynb: Introduces prompting techniques using the Flan-T5 model.​

- 2_Prompting_FlanT5_ICL_FewShot.ipynb: Demonstrates in-context learning and few-shot prompting with Flan-T5.​

- LoRA_Experiments.ipynb: Explores Low-Rank Adaptation (LoRA) experiments for model fine-tuning.​

- LoRA_FineTuning_FLAN_T5.ipynb: Details the process of fine-tuning the Flan-T5 model using LoRA.​

- LoRA_Solution.ipynb: Offers a solution notebook for implementing LoRA-based fine-tuning.​

- Solution1_DistilBERT_SST2_Transfer_Learning.ipynb: Showcases transfer learning with DistilBERT on the SST-2 dataset for sentiment analysis.​

- Solution2_FlanT5_SQuAD_v2_Question_Answering.ipynb: Demonstrates fine-tuning Flan-T5 on the SQuAD v2 dataset for question answering tasks.​

- Solution3_LoRA_FineTuning_Summarisation.ipynb: Presents a LoRA-based approach to fine-tuning models for text summarization.​

- Solution_PromptingFlanT5.ipynb: Provides solutions related to prompting techniques with Flan-T5.​

- TransferLearning.ipynb: Covers general concepts and methodologies in transfer learning for NLP.​

- Translation_FlanT5_Solution.ipynb: Offers a solution notebook for implementing translation tasks using Flan-T5.​

- Translation_FlanT5_with_Evaluation.ipynb: Extends translation tasks with evaluation metrics to assess model performance.
